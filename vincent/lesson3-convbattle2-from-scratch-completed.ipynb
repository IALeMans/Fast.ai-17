{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "from importlib import reload  # Python 3\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"convbattle2/\"\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "\n",
    "#batch_size=1\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches_channelfirst(dirname, gen=image.ImageDataGenerator(data_format=\"channels_first\"), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINCE KERAS MAKES USE OF INVERTED DROPOUT WE \"NEUTRALIZE\" proc_wgts(layer):\n",
    "#def proc_wgts(layer): return [o for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SINCE KERAS MAKES USE OF INVERTED DROPOUT WE \"NEUTRALIZE\" proc_wgts(layer):\n",
    "#def proc_wgts(layer, prev_p, new_p):\n",
    "def proc_wgts(layer, scal): return [o*scal for o in layer.get_weights()]\n",
    "\n",
    "\"\"\"\n",
    "def proc_wgts should be\n",
    "\n",
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    #transfer fc_layers weights to returned model.layers weights\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2, 1))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        #Dense(1000, activation='softmax')\n",
    "        Dense(2, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_ft(2)\n",
    "model.load_weights(model_path+'finetune.lesson2fromscratch.startlesson3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 551 images belonging to 2 classes.\n",
      "551/551 [==============================] - 15s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5055508043329352, 0.87658802177858441]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate finetune model\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n",
    "val_labels = onehot(val_batches.classes)\n",
    "\n",
    "val_data = np.rollaxis(load_array(model_path+'valid_data.bc'), 3, 1)\n",
    "\n",
    "model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2213 images belonging to 2 classes.\n",
      "Found 551 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# /!\\ shuffle batches is at FALSE :-0\n",
    "batches = get_batches_channelfirst(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches_channelfirst(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/batch_size))\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features\n",
      "(2213, 512, 14, 14)\n",
      "(551, 512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# highly computationnal opérations\n",
    "# activate only if you never computed nor saved theses files\n",
    "generate_feature = False\n",
    "\n",
    "if generate_feature:\n",
    "    print(\"generating features\")\n",
    "    val_features = conv_model.predict_generator(val_batches, validation_steps)\n",
    "    trn_features = conv_model.predict_generator(batches, steps_per_epoch)\n",
    "    save_array(model_path + 'train_convlayer_features.bc', trn_features)\n",
    "    save_array(model_path + 'valid_convlayer_features.bc', val_features)\n",
    "else:\n",
    "    print(\"loading features\")\n",
    "    trn_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "    val_features = load_array(model_path+'valid_convlayer_features.bc')\n",
    "    \n",
    "print (trn_features.shape)\n",
    "print (val_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "\n",
    "last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]\n",
    "#print (\"last convolutionnal layer id : \" + str(last_conv_idx))\n",
    "\n",
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)\n",
    "\n",
    "fc_layers = layers[last_conv_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such a finely tuned model needs to be updated very slowly!\n",
    "opt = RMSprop(lr=0.00001, rho=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()\n",
    "#get_fc_model include compiling op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2213 samples, validate on 551 samples\n",
      "Epoch 1/1\n",
      "2213/2213 [==============================] - 5s - loss: 0.0733 - acc: 0.9806 - val_loss: 0.5099 - val_acc: 0.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6f03a470>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(trn_features, trn_labels, epochs=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_model.save_weights(model_path+'dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if needed for restart\n",
    "#fc_model.load_weights(model_path+'dropout.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce overfitting > adding data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.2, \n",
    "       height_shift_range=0.2, shear_range=0.15, zoom_range=0.2, \n",
    "       channel_shift_range=15., horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2213 images belonging to 2 classes.\n",
      "Found 551 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches_channelfirst(path+'train', gen, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches_channelfirst(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "steps_per_epoch = int(np.ceil(batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#in order to allow data to flow through all the conv layers and our new dense layers, \n",
    "#we attach our fully connected model to the convolutional model--after ensuring that the convolutional layers \n",
    "#are not trainable:\n",
    "\n",
    "#if needed for restart\n",
    "#conv_layers = layers[:last_conv_idx+1]\n",
    "#conv_model = Sequential(conv_layers)\n",
    "\n",
    "# Look how easy it is to connect two models together!\n",
    "for layer in conv_model.layers: layer.trainable = False\n",
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can compile, train, and save our model as usual - note that we use *fit_generator()* since we want to pull random images from the directories on every batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.00000003, rho=0.7)\n",
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_model.save_weights(model_path + 'aug1.epoch00.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 65s - loss: 0.6095 - acc: 0.8690 - val_loss: 0.5006 - val_acc: 0.8875\n"
     ]
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)\n",
    "conv_model.save_weights(model_path + 'aug1.epoch01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 53s - loss: 0.5386 - acc: 0.8708 - val_loss: 0.4931 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)\n",
    "conv_model.save_weights(model_path + 'aug1.epoch02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 53s - loss: 0.5070 - acc: 0.8771 - val_loss: 0.4876 - val_acc: 0.8911\n"
     ]
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)\n",
    "conv_model.save_weights(model_path + 'aug1.epoch03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 53s - loss: 0.6147 - acc: 0.8671 - val_loss: 0.4825 - val_acc: 0.8911\n"
     ]
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)\n",
    "conv_model.save_weights(model_path + 'aug1.epoch04.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce overfitting > adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**all modern networks should use batchnorm, or something equivalent**. There are two reasons for this:\n",
    "1. Adding batchnorm to a model can result in **10x or more improvements in training speed**\n",
    "2. Because normalization greatly reduces the ability of a small number of outlying inputs to over-influence the training, it also tends to **reduce overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.load_weights(model_path + 'aug1.epoch03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in bn_model.layers: \n",
    "    if type(l)==Dense: l.set_weights(proc_wgts(l, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.pop()\n",
    "for layer in bn_model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_7 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 119,586,818\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 119,578,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2213 samples, validate on 551 samples\n",
      "Epoch 1/3\n",
      "2213/2213 [==============================] - 1s - loss: 0.6971 - acc: 0.6801 - val_loss: 0.7887 - val_acc: 0.6951\n",
      "Epoch 2/3\n",
      "2213/2213 [==============================] - 1s - loss: 0.4292 - acc: 0.8229 - val_loss: 0.4423 - val_acc: 0.8076\n",
      "Epoch 3/3\n",
      "2213/2213 [==============================] - 1s - loss: 0.3802 - acc: 0.8405 - val_loss: 0.3996 - val_acc: 0.8312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6e6b7b00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, epochs=3, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path+'bn.dropout20.epoch03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2213 samples, validate on 551 samples\n",
      "Epoch 1/2\n",
      "2213/2213 [==============================] - 1s - loss: 0.3044 - acc: 0.8717 - val_loss: 0.3964 - val_acc: 0.8385\n",
      "Epoch 2/2\n",
      "2213/2213 [==============================] - 1s - loss: 0.2926 - acc: 0.8735 - val_loss: 0.3935 - val_acc: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6e58c3c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, epochs=2, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2213 samples, validate on 551 samples\n",
      "Epoch 1/2\n",
      "2213/2213 [==============================] - 1s - loss: 0.2786 - acc: 0.8848 - val_loss: 0.4163 - val_acc: 0.8330\n",
      "Epoch 2/2\n",
      "2213/2213 [==============================] - 1s - loss: 0.2849 - acc: 0.8897 - val_loss: 0.4053 - val_acc: 0.8439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6e58c4e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, epochs=2, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#reload previous training\n",
    "#bn_model.load_weights(model_path+'bn.dropout20.epoch05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 57s - loss: 1.5154 - acc: 0.7494 - val_loss: 4.0882 - val_acc: 0.6842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6e2b4da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 56s - loss: 0.9484 - acc: 0.8100 - val_loss: 2.6715 - val_acc: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c47c6d8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#final_model.save_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 56s - loss: 0.5424 - acc: 0.8360 - val_loss: 0.7430 - val_acc: 0.8711\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 56s - loss: 0.4470 - acc: 0.8573 - val_loss: 0.6175 - val_acc: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c2e9d68>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path + 'final3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 57s - loss: 0.4422 - acc: 0.8446 - val_loss: 0.7405 - val_acc: 0.8348\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 55s - loss: 0.3221 - acc: 0.8916 - val_loss: 0.5672 - val_acc: 0.8457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c296470>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=2, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path + 'final3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.00003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 56s - loss: 0.3191 - acc: 0.8924 - val_loss: 0.4885 - val_acc: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c2964e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, \n",
    "                        validation_data=val_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#bn_model.save_weights(model_path + 'final4.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
